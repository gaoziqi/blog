## [未完待续] PostgreSQL\Greenplum Customer视角TODO
                       
### 作者      
digoal      
      
### 日期       
2017-10-17  
        
### 标签      
PostgreSQL , Greenplum , TODO         
                  
----                  
                   
## 背景   
https://wiki.postgresql.org/wiki/Todo


1. 物理流复制备库，支持对外部表执行DML操作，因为它不修改本地数据，没有风险。

此法，可以用于sharding库的中间层库的扩展。

a, b, c, d。A为主库，b,c,d为从库。a,b,c,d都作为中间库，使用postgres_fdw或其他fdw来做sharding。


2. 当使用GIN索引，并且大量使用了LIMIT来限制输出时，建议使用rum索引方法。避免bitmap index scan的耗时。

3. Greenplum：

自动垃圾回收，

优化器（非分布键的点查，现在建立master-segment的耗费较大，目测可能是串行的，节点多的情况下可能会比较糟糕。），

master到segment的连接保持。
  
segment之间的interconnect使用POOL连接池，减少motion时会话多的问题。

客户端连接池(顶住高并发)，

UPDATE和DELETE的排他锁改进，

订阅支持（类似逻辑复制）通过PGQ、消息队列...实现。

https://wiki.postgresql.org/wiki/PGQ_Tutorial
  
4. PostgreSQL，全表扫描支持通过hint或开关来使用directio，不占用OS CACHE，支持不加载到SHARED BUFFER。

5. PostgreSQL，每个DB有单独的REDO，DB支持热插拔。支持DB级的物理流复制。一个集群的数据库可以物理流复制的模式拷贝到另一个集群。

6. PostgreSQL，update returning old.column  
  
7. PostgreSQL，列存储，支持并行的列存储。

8. PostgreSQL， online ddl

9. pgbench 支持动态对象名，例如

```
\set suffix random(1,128)
\set id random(1,10000000)

select * from tbl:suffix where id=:id;
```

10. postgresql , 并行写wal。目前极限写压力下，WAL会成为瓶颈。  
  
11. postgresql , HTAP业务，资源队列管理，资源隔离，进程组管理.

12. grouping sets, rollup, cube, grouping id函数

http://blog.csdn.net/huang_xw/article/details/6402396

6 grouping()、grouping_id()、group_id()

6.1 grouping()
参数只有一个，而且必须为group by中出现的某一列，表示结果集的一行是否对该列做了grouping。对于对该列做了grouping的行而言，grouping()=0，反之为1；

6.2 grouping_id()
参数可以是多个，但必须为group by中出现的列。Grouping_id()的返回值其实就是参数中的每列的grouping()值的二进制向量，例如如果grouping(A)=1，grouping(B)=0，则grouping_id(A,B)的返回值就是二进制的10，转成10进制就是2。

6.3 group_id()
无参数。见上面的说明3），group by对某些列的集合会进行重复的grouping，而实际上绝大多数情况下对结果集中的这些重复行是不需要的，那就必须有办法剔出这些重复grouping的行。当结果集中有n条重复grouping而形成的行时，每行的group_id()分别是0,1,…,n，这样我们在条件中加入一个group_id()<1就可以剔出这些重复grouping的行了。

13. count(distinct) 目前只支持GroupAggregate，希望加入HashAggregate支持。同时支持HashAggregate的并行计算。

14. grant select on table 可以直接扣减 revoke select on table (column)。而不是只能grant select on table (column)来控制列的查询权限。

15. 统计信息、元数据信息快照，用于回放SQL，得到过去的执行计划信息。

16. 时间区间统计信息，统计信息分段。
  
17. 全局索引（分区表全局大索引），继承表全局大索引，多表伪索引。

18. pgsql, jsonb, json, hstore类型, range类型，支持内部KEY，VALUE，分布值的统计。

## 可视化生态：

19. 打通elastic和postgresql

pgsql的数据实时同步到elastic

https://developer.atlassian.com/blog/2015/02/realtime-requests-psql-elasticsearch/

https://github.com/jprante/elasticsearch-jdbc/wiki/Step-by-step-recipe-for-setting-up-the-river-with-PostgreSQL

https://github.com/jprante/elasticsearch-jdbc

pgsql直接访问elastic的数据

https://github.com/Mikulas/pg-es-fdw

20. 改进Orange，支持kibana所有可视化分析功能(图、地理、。。。。)

https://orange.biolab.si/  

21. 改进kibana，兼容postgresql
  
https://www.elastic.co/products/kibana
  
22. 改进qgis，稳定性，功能。云端GIS服务
  
https://qgis.org/en/site/
  
23. arcgis合作

24. 其他

http://openbouquet.io/

http://grafana.org/

http://redash.io/

人才方向，可视化，GIS

https://www.llamasoft.com/


25. postgresql, 更新合并，对应秒杀场景。

26. btree, gist等 (非gin)索引，支持pending list特性，提升含索引时的数据写入性能。

27. 社区roadmap

https://wiki.postgresql.org/wiki/Development_information

28. 一些社区企业ROADMAP

https://postgrespro.com/roadmap/

https://wiki.postgresql.org/wiki/NTT_roadmap


29. PostgreSQL 支持多种索引接口，支持自动选择合适的索引接口。

[《PostgreSQL 9种索引的原理和应用场景》](../201706/20170627_01.md)  

[《自动选择正确索引访问接口(btree,hash,gin,gist,sp-gist,brin,bitmap...)的方法》](../201706/20170617_01.md)  

30. query rewrite: 自动消除含unique 约束的group by, 例如 unique (c1,c2)， 自动消除 group by c1,c2,...；

31. postgresql 内置qps统计能力，增强pg_stats进程的功能。

32. 支持autovacuum, analyze的时间调度特性。可以配置到表、库级别。

33. gin支持条式返回，而非全量扫描index token后再返回。类似图式搜索的纵向(按点)返回和横向(层级返回)返回特性。
  
34. 1. split range 类型，返回数组

35. range数组操作

range[] - range[]  减
range[] + range[]  加
range[] & range[]  相交
| range[] , 合并相邻或重叠的元素

36. 支持rotate_table, 行，时间，SIZE等维度。

37. 支持returning语法，update时支持返回new, old值。


####  自适应同步模式
增加一个同步模式，remote_delay，当SYNC standby节点的WAL接收延迟低于这个值时，使用local的提交方式，用户COMMIT时，不进入等待队列。

例如remote_delay=8KB

那么当延迟低于8KB时，COMMIT或ROLLBACK不需要等待wal发送给备库，也就是说不需要进入sleep状态，本地REDO落盘后就提交。

####  单步入库优化
批量入库FEATURE

5个开关
是否允许自动回滚，
批量提交QUERY数，
批量提交tuple影响数，
idle in transaction 超时参数
是否开启自动的savepoint

自动分批提交特性，
如果没有在事务中，则自动开启BEGIN
到达阈值自动提交，并自动开启BEGIN

允许用户选择是否自动回滚

需要注意snapshot too old目前不处理写事务过旧。
需要注意9.6以前的版本，长事务可能导致膨胀。

应用场景
业务有大量的写入，
业务不想改SQL，就是单条单条插入
在同步多副本环境中特别有效。

效果与 sync=off 类似
但是记录批次可控，同时用户可感知，自动回滚到前一个savepoint。
安全性比sync=off高。

####  同步复制COMMIT延迟性能改进
目前同步复制，事务提交时在一个队列中等待WAL SENDER获取到的RMT LSN进行释放。 导致大量的MUTEX锁，同时很多进程的等待可能是无效的。

建议改成进程自己去询问RMT的LSN。

采用N个预先建立的primary到standby(s)的连接，根据主节点backend process PID取模，自动选择对应的链路去询问。

询问的LSN，分为几个(wal receiver(to buffer), wal write, wal flush ,wal apply)，询问到的LSN同时也通知给其他进程，其他进程也一样，自己去询问，同时接受别人询问的结果，一伙人去询问，可能效率更高。

进程根据不同的级别，选择需要比较的COMMIT LSN与RMT LSN，进行释放。

####  通过HINT 在dml中包含begin, end事务标记
减少交互次数，直接在QUERY中包含begin或END，ROLLBACK的包。

减少交互次数。

例如

select /*+ begin */ x from tbl;
自动开启事务

update /+ end */ t set xx=xx where xx;
update /+ commit */ t set xx=xx where xx;
自动提交当前事务

update /*+ rollback */ t set xx=xx where xx;
自动回滚当前事务

####  update|delete skip locked, nowait语法支持
目前PG支持select xxx for update skip locked , nowait.

但是不支持dml直接使用skip locked或者nowait

不利于低延迟的同类需求，需要发多次QUERY，开启事务来支持。

考虑添加直接的 update | delete skip locked, nowait 支持。

####  flashback query支持
允许用户设置表级vacuum 保留版本数，延迟VACUUM，同时延迟清理PG_XLOG，PG_CLOG。

用户指定falshback的时间，查询当时的表快照。

指定时间时，根据扫描到的XMIN或XMAX，在PG_XLOG中判断事务的提交时间，以及pg_clog中的事务结束状态，判断对用户是否可见。

如果事务提交时间早于FLASHBACK时间，并且PG_CLOG事务结束状态为提交，则对用户可见。

####  测试流量分流支持
通过定义规则，实现对测试流量的分流。

目前类似双十一或者其他公司在搞大促，或者对系统进行压测时，会模拟测试请求，这些请求不应该直接写入生产表。

可以写到影子表，例如TBL对应的影子表TBL_TEST。

PG可以根据客户端IP，客户端端口，application_name判断客户端是否属于测试来源。

用户可以配置规则，将属于测试来源的数据，在query rewrite这一层，把SQL改写掉，TBL_TEST替代TBL。

####  PG connection pool
内核层面的连接池。

连接池考虑多个分组，用户可以自定义使用哪个分组，或者默认根据QUERY的读写特性区分分组，或者根据QUERY的时长区分分组。

####  pg_hba.conf 支持控制superuser权限
目前pg_hba.conf仅支持角色名，库名。但是不能区分角色是普通用户还是超级用户。

增加这个功能可以用来控制更细粒度的权限。

例如禁止超级用户从远程登录。



####  释放CACHE


####  脏读功能

####  greenplum, 虚拟字段分区、分布键




####  负载策略，客户端就近选择节点
[思路]
一种负载策略。

读负载均衡、或多master的场景，客户端(最终客户端或proxy)选择就近节点。

例如多机房的场景，通过IP地址判断先从哪个节点读。

或者根据配置的节点顺序进行，直到取到正常节点为止(pg-jdbc目前是这种方式)。


####  同步复制自动降级，自动锁定（设置降级后的延迟阈值）。

####  日志分离
目前PG所有日志都打印在一起，不利于日志分析。
建议将审计日志、错误日志、慢SQL日志(包括auto_explain的)、其他日志分开成4个文件打印。


####  自动隐藏隐私信息（如create user password, alter role.... password)

####  sql 防火墙 

####  并行恢复、恢复过程允许只读操作，自动过滤不一致数据块，或自动使用旧快照。

####  在log_min_duration和 auto_explain记录的SQL中记录锁等待的时长

####  使用copy导入数据时，跳过异常的行。

####  walsender支持restore_command取文件传送给walreceiver



####  greenplum update,delete 锁粒度改进


####  greenplum segment节点开放读写


####  自动校准成本因子, 维度支持



####  支持多种数据块规格



####  批量数据提交的一种优化方法
PG如果能将插入这块的消息协议改进一下也许性能能提高比较多，将目前的 ESES..ES 改为 EEE...S 就好了。这样就可以实现类似于批量插入了。


####  pg_basebackup 过滤 hash index & unlogged table



####  [L] 支持多个密码，每个密码有对应的过期时间



####  [L] 表级访问秘钥



####  自动预热缓存




####  资源隔离 : 会话级、用户级、语句级、库级 内存、CPU单位时间、IOPS  限制



####  截断聚合
截断头尾百分比后输出聚合值。类似的应用场景有排除噪点、干扰数据后的聚合。
例如统计tps的平均值，方差，标准差。但是由于一些干扰因素可能导致测试TPS时造成了一些干扰，使用这种方法可以过滤掉一些干扰数据。

http://api.pgxn.org/src/trimmed_aggregates/




####  协议层压缩支持


####  基于hash聚合的count distinct支持



####  跨库分表


####  假设索引


####  plan hint 支持


####  改进垃圾回收进程，只保留需要的tuple版本，而不是最早事务之前的所有版本。


100. 便捷的各种数据类产品打通，同步。

101. GPDB, 支持MERGE INSERT

102. GPDB，支持GIN索引

103. postgresql, pg_stat_all_tables, 建议添加autovacuum, auto analyze, analyze, vacuum等存储为数组，记录最近N次的操作统计信息，包括每次扫描了多少BLOCK，产生了多少DIRTY PAGE等等。

便于突发的IO或CPU的排错。 目前只记录最后一次，而且统计信息只能到LOG里面翻看，不够便捷。 

-[ RECORD 57 ]------+---------------------------------------
relid               | 16794
schemaname          | public
relname             | xxx
seq_scan            | 0
seq_tup_read        | 0
idx_scan            | 7878
idx_tup_fetch       | 29897
n_tup_ins           | 48337
n_tup_upd           | 0
n_tup_del           | 0
n_tup_hot_upd       | 0
n_live_tup          | 765193
n_dead_tup          | 0
n_mod_since_analyze | 13404
last_vacuum         | 
last_autovacuum     | 2018-01-16 17:42:57.694793+08
last_analyze        | 
last_autoanalyze    | 2018-01-13 09:13:02.457322+08
vacuum_count        | 0
autovacuum_count    | 1
analyze_count       | 0
autoanalyze_count   | 1


104. PG，GP， 数据采样（已支持）、脱敏功能。

105. 数据类型， 透明加密功能. 

106. Greenplum, postgresql , 加入roaringbitmap，同时支持 多阶段并行聚合函数。

107. PostgreSQL ,在创建分区表索引时，支持每个分区并行创建。


108. PostgreSQL , paralle append + 外部表 + pushdown，可以实现sharding 架构下的并发计算。（例如求SUM,AVG,COUNG,MIN,MAX等，不过针对外部表的parallel append内核层面还没有支持好，需要CUSTOM SCAN）

109. PostgreSQL, 支持单个索引含多颗树。

[《PostgreSQL 店铺运营实践 - JSON[]数组 内部标签数据等值、范围检索100倍+加速示例》](../201802/20180208_01.md)  

110. 支持分区索引。一个索引根据某些表达式、字段HASH、范围分区，构成多颗树。（时间、空间、多个属性）

111. GIN索引支持范围扫描（目前仅支持等值(包含、相交等)扫描）。

arr >>= ? and arr <<=?

使用新的操作符代替>=, <=，实现元素的区间扫描。


112. PostgreSQL, GPDB , jsonbd 一种内置压缩能力的JSON类型，实际上数据库内核也可以在数组、全文检索等其他多值类型上增加类似的压缩功能（相当于内置的数据字典能力），将字典化这个工作转嫁给数据库来实现。   
  
https://github.com/postgrespro/jsonbd  
  
```
CREATE EXTENSION jsonbd;
CREATE TABLE t(a JSONB COMPRESSION jsonbd);
```

113. online split, merge 分区表.

114. postgresql, gpdb 支持动态执行计划，执行过程中根据实际的NODE扫描并返回的数据的统计信息，动态调整执行计划。

115. timescale , postgresql, 提供数据自动老化能力（自动有损压缩）。
  
116. postgresql, 支持具备阶段性可靠性的UNLOGGED TABLE，加速导入。
  
117. postgresql , skip locked , 返回未获得锁的行。以便再次处理。
  
<a rel="nofollow" href="http://info.flagcounter.com/h9V1"  ><img src="http://s03.flagcounter.com/count/h9V1/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_12/viewers_0/labels_0/pageviews_0/flags_0/"  alt="Flag Counter"  border="0"  ></a>  
  

